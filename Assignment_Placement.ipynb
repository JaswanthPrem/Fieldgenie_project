{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nujmLTl1Spqv",
        "outputId": "898b20ea-495a-4e01-deda-1f518fe941e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.5/131.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.8/76.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q pypdf chromadb sentence-transformers groq langgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgnylfw4SqWU",
        "outputId": "18bafd87-2e05-48f6-9ba5-585d7a37364f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-0.2.4-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: groq<1,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from langchain-groq) (0.18.0)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.33 in /usr/local/lib/python3.11/dist-packages (from langchain-groq) (0.3.40)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (4.12.2)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain-groq) (0.3.11)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain-groq) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain-groq) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain-groq) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain-groq) (24.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain-groq) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-groq) (3.10.15)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-groq) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-groq) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-groq) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-groq) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-groq) (2.3.0)\n",
            "Downloading langchain_groq-0.2.4-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: langchain-groq\n",
            "Successfully installed langchain-groq-0.2.4\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-groq\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNG6900ZSukK",
        "outputId": "767b3def-e623-4523-8938-894ae5374ced"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the path of the folder containing PDFs: /content/KB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 0\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 0\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 1\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 1\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 2\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 2\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 3\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 3\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 4\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 4\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 5\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 5\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 6\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 6\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 7\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 7\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 8\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 8\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 9\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 9\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 10\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 10\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 11\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 11\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 12\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 12\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 13\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 13\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 14\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 14\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 15\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 15\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 16\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 16\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 17\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 17\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 18\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 18\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 19\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 19\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 20\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 20\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 21\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 21\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 22\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 22\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 23\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 23\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 24\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 24\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 25\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 25\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 26\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 26\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 27\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 27\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome to the PDF Chatbot. Type 'exit' to quit.\n",
            "You: suggest me places to see in ayodhya\n",
            "Bot: Based on the uploaded PDF document \"Ayodhya: The Sacred City\", here are some suggested places to see in Ayodhya:\n",
            "\n",
            "1. **Ram Janmabhoomi Temple**: The most famous religious site in Ayodhya, believed to be the birthplace of Lord Rama.\n",
            "2. **Hanuman Garhi**: A prominent temple dedicated to Lord Hanuman, featuring a steep climb of 76 steps. Devotees visit to seek blessings before heading to Ram Janmabhoomi.\n",
            "3. **Kanak Bhawan**: A temple known for its stunning idols of Lord Rama and Goddess Sita adorned with gold ornaments.\n",
            "4. **Sarayu River**: A holy river where thousands of devotees take a holy dip on Kartik Purnima.\n",
            "\n",
            "Additionally, Ayodhya Airport, improved rail and road networks, and new accommodations including luxury hotels and resorts are also emerging, making it easier for tourists to visit and explore the city.\n",
            "You: give me 3 days plan to visit praygraj\n",
            "Bot: Based on the provided information, here's a suggested 3-day plan to visit Prayagraj:\n",
            "\n",
            "**Day 1:**\n",
            "\n",
            "1. Morning: Visit the Triveni Sangam, the most sacred spot in Prayagraj, and take a dip in the holy waters.\n",
            "2. Afternoon: Explore the nearby Kumbh Mela grounds, which is a significant pilgrimage site, especially during Mahashivratri.\n",
            "3. Evening: Visit the famous Lord Shiva temple located on the banks of the Yamuna River and experience the spiritual aura of the city.\n",
            "\n",
            "**Day 2:**\n",
            "\n",
            "1. Morning: Visit the Anand Bhavan, the ancestral home of the Nehru family, to understand the rich history and legacy of the city.\n",
            "2. Afternoon: Explore the city's cultural significance by attending a festival or event, such as the Kumbh Mela or Magh Mela, depending on the time of year.\n",
            "3. Evening: Experience the vibrant atmosphere of the city by visiting the local markets and trying some of the local cuisine.\n",
            "\n",
            "**Day 3:**\n",
            "\n",
            "1. Morning: Take a tour of the Prayagraj Airport (Bamrauli Airport) and learn about its significance in connecting the city to major destinations.\n",
            "2. Afternoon: Visit the Prayagraj Junction railway station and take a stroll along the banks of the Yamuna River to appreciate the city's natural beauty.\n",
            "3. Evening: End your trip by attending a cultural event or festival, such as Diwali or Holi, to experience the city's vibrant culture and heritage.\n",
            "\n",
            "Note: This is just a suggested itinerary and can be customized based on your personal preferences and interests.\n",
            "You: tell me about BHU\n",
            "Bot: Banaras Hindu University (BHU) is a prominent residential university established in 1916 by Pandit Madan Mohan Malaviya. It is one of Asia's largest residential universities and is home to the sprawling campus where the Vishwanath Temple is located. The temple's design reflects traditional Hindu architecture and serves as a center for spiritual learning.\n",
            "You: im visiting thisitng these 3 places give me trip plan for 8 days\n",
            "Bot: Based on the provided information, here's an 8-day trip plan for you to visit the following places in Prayagraj:\n",
            "\n",
            "Day 1: Arrival and Exploration of Anand Bhavan\n",
            "\n",
            "- Arrive in Prayagraj\n",
            "- Visit the famous Anand Bhavan, the ancestral home of the Nehru family\n",
            "- Explore the nearby areas and get familiar with the local culture\n",
            "\n",
            "Day 2: Triveni Sangam\n",
            "\n",
            "- Start the day by visiting the Triveni Sangam, the most sacred spot in Prayagraj\n",
            "- Take a dip in the holy waters, especially if you're visiting during the Kumbh Mela\n",
            "- Visit the nearby Kumbh Mela site to experience the grandness of the spiritual gathering\n",
            "\n",
            "Day 3-4: Kumbh Mela (If visiting during the Kumbh Mela) or Explore the City\n",
            "\n",
            "- If you're visiting during the Kumbh Mela, spend the next two days exploring the festival and its surroundings\n",
            "- Alternatively, explore the city and visit local markets, temples, and other attractions\n",
            "\n",
            "Day 5: Festivals and Cultural Significance\n",
            "\n",
            "- Visit the Magh Mela site and experience the annual fair held at the Sangam\n",
            "- Celebrate Diwali & Holi with the locals and experience the city's enthusiasm for these festivals\n",
            "- Attend a Navratri & Dussehra celebration to experience the city's cultural significance\n",
            "\n",
            "Day 6: Kartik Purnima\n",
            "\n",
            "- Visit the Sarayu River and take a holy dip with thousands of devotees\n",
            "- Explore the surrounding areas and experience the local culture\n",
            "\n",
            "Day 7-8: Leisure and Departure\n",
            "\n",
            "- Spend the last two days of your trip relaxing and exploring the city\n",
            "- Visit any attractions you might have missed earlier or revisit your favorite spots\n",
            "- Depart from Prayagraj on the last day of your trip\n",
            "\n",
            "Note: The itinerary may vary depending on the time of year you visit and the availability of the Kumbh Mela.\n",
            "You: tell me about delhi\n",
            "Bot: I'm not aware of what you're asking. The provided information appears to be about the cities of Varanasi and Ayodhya in India, their historical and cultural significance, and tourist attractions.\n",
            "You: q\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import chromadb\n",
        "from pypdf import PdfReader\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain_groq import ChatGroq\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from dataclasses import dataclass\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Set up Groq AI client\n",
        "groq_client = ChatGroq(api_key=\"gsk_19RFbIOTiZEEMZlOTuOEWGdyb3FYd1M9gff6CViZ93d8lCR*****\", model_name=\"llama-3.1-8b-instant\")\n",
        "\n",
        "# Function to load and process PDFs from a folder\n",
        "def load_pdfs_from_folder(folder_path):\n",
        "    all_texts = []\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        if file_name.endswith(\".pdf\"):\n",
        "            file_path = os.path.join(folder_path, file_name)\n",
        "            reader = PdfReader(file_path)\n",
        "            text = \"\".join(page.extract_text() or \"\" for page in reader.pages)\n",
        "            all_texts.append(text)\n",
        "    return all_texts\n",
        "\n",
        "def split_text_into_chunks(texts, chunk_size=500):\n",
        "    chunks = []\n",
        "    for text in texts:\n",
        "        chunks.extend([text[i:i+chunk_size] for i in range(0, len(text), chunk_size)])\n",
        "    return chunks\n",
        "\n",
        "# Ask user for folder input\n",
        "folder_path = input(\"Enter the path of the folder containing PDFs: \")\n",
        "if not os.path.exists(folder_path) or not os.path.isdir(folder_path):\n",
        "    print(\"Invalid folder path. Please enter a valid path.\")\n",
        "    exit()\n",
        "\n",
        "# Process all PDFs in the folder\n",
        "pdf_texts = load_pdfs_from_folder(folder_path)\n",
        "chunks = split_text_into_chunks(pdf_texts)\n",
        "\n",
        "# Vectorize the text\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "embeddings = embedding_model.encode(chunks)\n",
        "\n",
        "# Store embeddings in ChromaDB\n",
        "client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
        "collection = client.get_or_create_collection(name=\"pdf_documents\")\n",
        "\n",
        "for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):\n",
        "    collection.add(documents=[chunk], embeddings=[embedding.tolist()], ids=[str(i)])\n",
        "\n",
        "@dataclass\n",
        "class RAGState:\n",
        "    query: str\n",
        "    context: str = \"\"\n",
        "    response: str = \"\"\n",
        "\n",
        "# Retrieve relevant text chunks\n",
        "def retrieve_relevant_chunks(state):\n",
        "    query = state.query.lower()\n",
        "    query_embedding = embedding_model.encode([query])[0]\n",
        "    results = collection.query(query_embeddings=[query_embedding.tolist()], n_results=3)\n",
        "\n",
        "    if results and results['documents']:\n",
        "        return RAGState(query=query, context=\"\\n\".join(results['documents'][0]))\n",
        "    return RAGState(query=query, response=\"I'm not aware of what you're asking.\")\n",
        "\n",
        "# Generate response\n",
        "def generate_response(state):\n",
        "    query = state.query\n",
        "    context = state.context if state.context else \"I'm not aware of what you're asking.\"\n",
        "    prompt = f\"\"\"\n",
        "    You are an AI chatbot that answers questions based on the uploaded PDFs.\n",
        "    If the question is unrelated to the documents, say: \"I'm not aware of what you're asking.\"\n",
        "\n",
        "    Context:\n",
        "    {context}\n",
        "\n",
        "    Question: {query}\n",
        "    Answer:\n",
        "    \"\"\"\n",
        "    response = groq_client.invoke(prompt)\n",
        "    return RAGState(query=query, response=response)\n",
        "\n",
        "# Define LangGraph Workflow\n",
        "workflow = StateGraph(RAGState)\n",
        "workflow.add_node(\"retrieve\", retrieve_relevant_chunks)\n",
        "workflow.add_node(\"generate\", generate_response)\n",
        "workflow.set_entry_point(\"retrieve\")\n",
        "workflow.add_edge(\"retrieve\", \"generate\")\n",
        "workflow.add_edge(\"generate\", END)\n",
        "graph = workflow.compile()\n",
        "\n",
        "# Chat function\n",
        "def chat_with_pdfs():\n",
        "    print(\"Welcome to the PDF Chatbot. Type 'exit' to quit.\")\n",
        "    while True:\n",
        "        query = input(\"You: \")\n",
        "        if query.lower() in [\"exit\", \"quit\", \"q\"]:\n",
        "            break\n",
        "\n",
        "        result = graph.invoke(RAGState(query=query))\n",
        "        state = RAGState(**result)\n",
        "\n",
        "        if isinstance(result['response'], str):\n",
        "            print(f\"Bot: {result['response']}\")\n",
        "        else:\n",
        "            print(f\"Bot: {result['response'].content}\")\n",
        "\n",
        "# Run the chatbot\n",
        "chat_with_pdfs()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
